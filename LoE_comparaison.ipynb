{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3fff9d-3436-4e37-9274-5be4b30b7c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "from tqdm import tqdm\n",
    "from classes.loe import LoE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, average_precision_score\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import import_ipynb\n",
    "import data_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb40a297-6306-4df4-bdf2-d20a1c61b308",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4311b242-11e0-478f-978d-3056462dd232",
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_summary_clf(ytrain_true, yval_true, ytest_true, ytrain_pred, yval_pred, ytest_pred):\n",
    "    # for global model\n",
    "    Summary_index = ['Training set', 'Validation set', 'Testing set']\n",
    "    Summary_columns = ['Accuracy', 'F1_score', 'Precision_score']\n",
    "    Summary_results = pandas.DataFrame(index=Summary_index, columns=Summary_columns)\n",
    "\n",
    "    # performance of the global model\n",
    "    Summary_results.loc[Summary_index[0], Summary_columns[0]] = round(accuracy_score(ytrain_true, ytrain_pred)*100, 2)\n",
    "    Summary_results.loc[Summary_index[0], Summary_columns[1]] = round(f1_score(ytrain_true, ytrain_pred)*100, 2)\n",
    "    Summary_results.loc[Summary_index[0], Summary_columns[2]] = round(average_precision_score(ytrain_true, ytrain_pred)*100, 2)\n",
    "    \n",
    "    Summary_results.loc[Summary_index[1], Summary_columns[0]] = round(accuracy_score(yval_true, yval_pred)*100, 2)\n",
    "    Summary_results.loc[Summary_index[1], Summary_columns[1]] = round(f1_score(yval_true, yval_pred)*100, 2)\n",
    "    Summary_results.loc[Summary_index[1], Summary_columns[2]] = round(average_precision_score(yval_true, yval_pred)*100, 2)\n",
    "    \n",
    "    Summary_results.loc[Summary_index[2], Summary_columns[0]] = round(accuracy_score(ytest_true, ytest_pred)*100, 2)\n",
    "    Summary_results.loc[Summary_index[2], Summary_columns[1]] = round(f1_score(ytest_true, ytest_pred)*100, 2)\n",
    "    Summary_results.loc[Summary_index[2], Summary_columns[2]] = round(average_precision_score(ytest_true, ytest_pred)*100, 2)\n",
    "    \n",
    "    return Summary_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596e18ef-666d-43bb-a4dd-e7eda20be5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def C_validation_clf(X_train, X_val, y_train, y_val, n_experts):     \n",
    "    n_samples, n_features = X_train.shape\n",
    "    C_params, scores = np.arange(0.5, 10.0, 0.5) * n_samples, []\n",
    "\n",
    "    for C in C_params:\n",
    "        if n_experts==2:\n",
    "            loe = LoE(pool_classifiers=[CustomSvm(C=C, random_state=40), CustomSvm(C=C, random_state=40)],\n",
    "                      step_size=2, iterations=20, maximum_selected_features=None, step_callback=None, random_state=40)\n",
    "        elif n_experts==3:\n",
    "            loe = LoE(pool_classifiers=[CustomSvm(C=C, random_state=40), CustomSvm(C=C, random_state=40), CustomSvm(C=C, random_state=40)],\n",
    "                      step_size=2, iterations=20, maximum_selected_features=None, step_callback=None, random_state=40)\n",
    "\n",
    "        loe.fit(X=X_train, y=y_train)\n",
    "        scores.append(accuracy_score(y_val, loe.predict(X_val)))\n",
    "    return C_params[np.argmax(scores)]\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6408b2-45bd-4d48-8b34-cf7dbadfc6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSvm:\n",
    "    def __init__(self, penalty='l2', loss='squared_hinge', dual='auto', tol=0.0001, C=1.0, multi_class='ovr', fit_intercept=True, intercept_scaling=1, class_weight=None, verbose=0, random_state=None, max_iter=1000):\n",
    "        self.penalty=penalty\n",
    "        self.loss=loss\n",
    "        self.dual=dual\n",
    "        self.tol=tol\n",
    "        self.C=C\n",
    "        self.multi_class=multi_class\n",
    "        self.fit_intercept=fit_intercept\n",
    "        self.intercept_scaling=intercept_scaling\n",
    "        self.class_weight=class_weight\n",
    "        self.verbose=verbose\n",
    "        self.random_state=random_state\n",
    "        self.max_iter=max_iter\n",
    "        \n",
    "        self.Svm = LinearSVC(penalty=self.penalty, loss=self.loss, dual=self.dual, tol=self.tol, C=self.C, multi_class=self.multi_class, fit_intercept=self.fit_intercept, intercept_scaling=self.intercept_scaling, class_weight=self.class_weight, verbose=self.verbose, random_state=self.random_state, max_iter=self.max_iter)\n",
    "        self.unique_class_value = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.unique_class_value = np.unique(y)\n",
    "        if self.unique_class_value.size == 2:\n",
    "            self.Svm.fit(X, y)\n",
    "            \n",
    "    def predict(self, X):\n",
    "        return self.Svm.predict(X) if self.unique_class_value.size == 2 else self.unique_class_value[0] * np.ones(X.shape[0])\n",
    "\n",
    "    def class_weight_(self):\n",
    "        return self.Svm.class_weight_ if self.unique_class_value.size == 2 else np.ones(2)\n",
    "\n",
    "    def get_params(self):\n",
    "        return self.Svm.get_params()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2ad75a-9c30-4d5c-a99d-f873943b401d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_loe(data, target_name, train_size=0.7, n_experts=2, times=1):\n",
    "    # uncouping X and y\n",
    "    X, y = data_analysis.uncouping_x_y(data.copy(), target_name)\n",
    "    \n",
    "    for i in tqdm(np.arange(times), desc=\"For Random Data Split = \"+str(times)+\" â€¦\", total=times, position=0):\n",
    "        # split the dataset X into the training set X_train and temporary set X_temp\n",
    "        X_train, X_temp, y_train, y_temp = train_test_split(X, y, train_size = train_size, stratify=y, random_state=i)\n",
    "        # split the dataset X_temp into the validation set X_val and testing set X_test\n",
    "        X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, train_size = 0.5, stratify=y_temp, random_state=0)\n",
    "        X_train, X_val, X_test = data_analysis.reset_index_data(data_1=X_train, data_2=X_val, data_3=X_test, data_4=None)\n",
    "        \n",
    "        # data encoding (target encoding for category variables) and scaling (example : 'TargetEncoder', 'OrdinalEncoder', etc...)\n",
    "        X_train_enc, X_val_enc, X_test_enc = data_analysis.data_processing(xtrain=X_train.copy(), ytrain=y_train.copy(), xtest_1=X_val.copy(), xtest_2=X_test.copy(), xtest_3=None, enc_type='OneHotEncoder', scale_type='Standardscaler')\n",
    "        X_train_enc, X_val_enc, X_test_enc = X_train_enc.values.copy(), X_val_enc.values.copy(), X_test_enc.values.copy()\n",
    "\n",
    "        if i == 0:\n",
    "            print('*********************************************** The League of Experts ***********************************************')\n",
    "            print(f'Training_set = {round((train_size * 100))}%, Validation_set = {round(((1 - train_size)/2) * 100)}%, Test_set = {round(((1 - train_size)/2) * 100)}%, , n_experts = {n_experts}, kernel = linear, class_weights = None, C_validation = True, times = {times}')\n",
    "\n",
    "        C_param =  C_validation_clf(X_train_enc.copy(), X_val_enc.copy(), y_train.copy(), y_val.copy(), n_experts)\n",
    "        if n_experts==2:\n",
    "            loe = LoE(pool_classifiers=[CustomSvm(C=C_param, random_state=40), CustomSvm(C=C_param, random_state=40)],\n",
    "                      step_size=2, iterations=20, maximum_selected_features=None, step_callback=None, random_state=40)\n",
    "        elif n_experts==3:\n",
    "            loe = LoE(pool_classifiers=[CustomSvm(C=C_param, random_state=40), CustomSvm(C=C_param, random_state=40), CustomSvm(C=C_param, random_state=40)],\n",
    "                      step_size=2, iterations=20, maximum_selected_features=None, step_callback=None, random_state=40)\n",
    "    \n",
    "        loe.fit(X=X_train_enc, y=y_train)\n",
    "\n",
    "        # predictions\n",
    "        y_train_preds = loe.predict(X_train_enc)\n",
    "        y_val_preds = loe.predict(X_val_enc)\n",
    "        y_test_preds = loe.predict(X_test_enc)\n",
    "\n",
    "        # get summary\n",
    "        summary_random = results_summary_clf(y_train, y_val, y_test, y_train_preds, y_val_preds, y_test_preds)\n",
    "        # get summary on data random_state\n",
    "        summary_data_random = summary_random if i == 0 else summary_data_random + summary_random\n",
    "    summary = (summary_data_random / times).astype('float64').round(2)\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1646f0e0-f781-4441-9da0-53e14dfe16b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
